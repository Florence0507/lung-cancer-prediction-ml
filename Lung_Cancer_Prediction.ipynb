{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# ü´Å Lung Cancer Prediction using Logistic Regression\n",
    "\n",
    "**Author:** Florencekumari Makwana  \n",
    "**Dataset:** Lung Cancer Survey Dataset (309 records, 15 features)  \n",
    "**Goal:** Predict whether a patient has lung cancer based on lifestyle and symptom data using Logistic Regression.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Project Overview\n",
    "\n",
    "Lung cancer is one of the leading causes of cancer-related deaths worldwide. Early detection significantly improves survival rates. In this project, we build a **binary classification model** using Logistic Regression to predict lung cancer presence based on survey responses about symptoms and lifestyle habits.\n",
    "\n",
    "### Workflow\n",
    "1. Data Loading & Exploration\n",
    "2. Data Preprocessing\n",
    "3. Train/Test Split\n",
    "4. Model Training (Logistic Regression)\n",
    "5. Model Evaluation (Accuracy, Precision, Recall, Specificity, Confusion Matrix)\n",
    "6. Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-md",
   "metadata": {},
   "source": [
    "## üì¶ 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    confusion_matrix, roc_auc_score, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_theme(style='whitegrid', palette='muted')\n",
    "print('Libraries loaded successfully ‚úÖ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-md",
   "metadata": {},
   "source": [
    "## üìÇ 2. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('survey_lung_cancer.csv')\n",
    "\n",
    "# Strip whitespace from column names (some have trailing spaces)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'Columns: {list(df.columns)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda-md",
   "metadata": {},
   "source": [
    "## üîç 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info and statistics\n",
    "print('=== Dataset Info ===')\n",
    "df.info()\n",
    "print('\\n=== Missing Values ===')\n",
    "print(df.isnull().sum())\n",
    "print('\\n=== Statistical Summary ===')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Count plot\n",
    "counts = df['LUNG_CANCER'].value_counts()\n",
    "axes[0].bar(counts.index, counts.values, color=['#2ecc71', '#e74c3c'], edgecolor='black', width=0.5)\n",
    "axes[0].set_title('Lung Cancer Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Lung Cancer')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels(['NO', 'YES'])\n",
    "for i, v in enumerate(counts.values):\n",
    "    axes[0].text(counts.index[i], v + 1, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(counts.values, labels=['NO', 'YES'], autopct='%1.1f%%',\n",
    "            colors=['#2ecc71', '#e74c3c'], startangle=90,\n",
    "            wedgeprops={'edgecolor': 'white', 'linewidth': 2})\n",
    "axes[1].set_title('Lung Cancer Proportion', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f'\\nClass balance ‚Äî YES: {counts.get(\"YES\", 0)} | NO: {counts.get(\"NO\", 0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda-gender-age",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender & Age distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Gender distribution by lung cancer\n",
    "gender_lc = df.groupby(['GENDER', 'LUNG_CANCER']).size().unstack(fill_value=0)\n",
    "gender_lc.plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'],\n",
    "               edgecolor='black', rot=0)\n",
    "axes[0].set_title('Gender vs Lung Cancer', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Gender')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].legend(['NO', 'YES'])\n",
    "\n",
    "# Age distribution\n",
    "axes[1].hist(df[df['LUNG_CANCER'] == 'YES']['AGE'], bins=15, alpha=0.7,\n",
    "             color='#e74c3c', label='YES', edgecolor='black')\n",
    "axes[1].hist(df[df['LUNG_CANCER'] == 'NO']['AGE'], bins=15, alpha=0.7,\n",
    "             color='#2ecc71', label='NO', edgecolor='black')\n",
    "axes[1].set_title('Age Distribution by Lung Cancer', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Age')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gender_age_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda-symptoms",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symptom feature comparison (binary features: 1=No, 2=Yes)\n",
    "symptom_cols = [\n",
    "    'SMOKING', 'YELLOW_FINGERS', 'ANXIETY', 'PEER_PRESSURE',\n",
    "    'CHRONIC DISEASE', 'FATIGUE', 'ALLERGY', 'WHEEZING',\n",
    "    'ALCOHOL CONSUMING', 'COUGHING', 'SHORTNESS OF BREATH',\n",
    "    'SWALLOWING DIFFICULTY', 'CHEST PAIN'\n",
    "]\n",
    "\n",
    "# Calculate % of positive (value=2) symptom per lung cancer class\n",
    "temp = df.copy()\n",
    "temp['LUNG_CANCER_BIN'] = (temp['LUNG_CANCER'] == 'YES').astype(int)\n",
    "\n",
    "symptom_rates = {}\n",
    "for col in symptom_cols:\n",
    "    yes_rate = ((temp[temp['LUNG_CANCER_BIN'] == 1][col] == 2).mean() * 100)\n",
    "    no_rate  = ((temp[temp['LUNG_CANCER_BIN'] == 0][col] == 2).mean() * 100)\n",
    "    symptom_rates[col] = {'Lung Cancer: YES': yes_rate, 'Lung Cancer: NO': no_rate}\n",
    "\n",
    "symptom_df = pd.DataFrame(symptom_rates).T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "x = np.arange(len(symptom_df))\n",
    "width = 0.35\n",
    "bars1 = ax.bar(x - width/2, symptom_df['Lung Cancer: YES'], width,\n",
    "               label='Lung Cancer: YES', color='#e74c3c', alpha=0.85, edgecolor='black')\n",
    "bars2 = ax.bar(x + width/2, symptom_df['Lung Cancer: NO'], width,\n",
    "               label='Lung Cancer: NO', color='#2ecc71', alpha=0.85, edgecolor='black')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(symptom_df.index, rotation=45, ha='right', fontsize=10)\n",
    "ax.set_ylabel('% of Patients with Symptom', fontsize=12)\n",
    "ax.set_title('Symptom Prevalence by Lung Cancer Status', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_ylim(0, 110)\n",
    "plt.tight_layout()\n",
    "plt.savefig('symptom_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocess-md",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è 4. Data Preprocessing\n",
    "\n",
    "Steps:\n",
    "- Encode the target variable (`LUNG_CANCER`): `YES ‚Üí 1`, `NO ‚Üí 0`\n",
    "- Encode the `GENDER` column using one-hot encoding\n",
    "- Verify there are no missing values\n",
    "- Separate features (`X`) and target (`y`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocess-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target variable\n",
    "df['LUNG_CANCER'] = df['LUNG_CANCER'].map({'YES': 1, 'NO': 0})\n",
    "\n",
    "# Check for missing values\n",
    "missing = df.isnull().sum().sum()\n",
    "print(f'Missing values: {missing} ‚Äî {\"‚úÖ None found\" if missing == 0 else \"‚ö†Ô∏è Dropping rows with NaN\"}')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['LUNG_CANCER'])\n",
    "y = df['LUNG_CANCER'].astype(int)\n",
    "\n",
    "# One-hot encode categorical features (GENDER)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(f'Feature matrix shape: {X.shape}')\n",
    "print(f'Target distribution ‚Äî 1 (YES): {y.sum()} | 0 (NO): {(y == 0).sum()}')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-md",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è 5. Train / Test Split\n",
    "\n",
    "We split the dataset into **80% training** and **20% testing** using a fixed `random_state=42` for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "print(f'Training samples : {len(X_train)}')\n",
    "print(f'Testing samples  : {len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-md",
   "metadata": {},
   "source": [
    "## ü§ñ 6. Model Training ‚Äî Logistic Regression\n",
    "\n",
    "Logistic Regression estimates the probability of class membership using the **sigmoid function**:\n",
    "\n",
    "$$P(y=1 | X) = \\frac{1}{1 + e^{-(w^T X + b)}}$$\n",
    "\n",
    "We set `max_iter=500` to ensure convergence on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = LogisticRegression(max_iter=500, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Display model coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model.coef_[0]\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "print('Model trained successfully ‚úÖ')\n",
    "print('\\nTop 5 most influential features (positive):')\n",
    "print(coef_df.head())\n",
    "print('\\nBottom 5 features (negative influence):')\n",
    "print(coef_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coef-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['#e74c3c' if c > 0 else '#3498db' for c in coef_df['Coefficient']]\n",
    "plt.barh(coef_df['Feature'], coef_df['Coefficient'], color=colors, edgecolor='black')\n",
    "plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "plt.title('Logistic Regression ‚Äî Feature Coefficients', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_coefficients.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-md",
   "metadata": {},
   "source": [
    "## üìä 7. Model Evaluation\n",
    "\n",
    "We evaluate the model using the following metrics:\n",
    "\n",
    "| Metric | Formula | What it measures |\n",
    "|--------|---------|------------------|\n",
    "| **Accuracy** | (TP+TN)/(TP+TN+FP+FN) | Overall correct predictions |\n",
    "| **Precision** | TP/(TP+FP) | Of predicted positives, how many are correct |\n",
    "| **Recall (Sensitivity)** | TP/(TP+FN) | Of actual positives, how many were found |\n",
    "| **Specificity** | TN/(TN+FP) | Of actual negatives, how many were correctly identified |\n",
    "| **ROC-AUC** | Area under ROC curve | Overall discrimination ability |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "accuracy  = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall    = recall_score(y_test, y_pred)\n",
    "roc_auc   = roc_auc_score(y_test, y_prob)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "tn, fp, fn, tp = confusion.ravel()\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "print('=' * 40)\n",
    "print('       MODEL EVALUATION METRICS')\n",
    "print('=' * 40)\n",
    "print(f'  Accuracy    : {accuracy:.4f}  ({accuracy*100:.2f}%)')\n",
    "print(f'  Precision   : {precision:.4f}  ({precision*100:.2f}%)')\n",
    "print(f'  Recall      : {recall:.4f}  ({recall*100:.2f}%)')\n",
    "print(f'  Specificity : {specificity:.4f}  ({specificity*100:.2f}%)')\n",
    "print(f'  ROC-AUC     : {roc_auc:.4f}')\n",
    "print('=' * 40)\n",
    "print(f'\\nConfusion Matrix:')\n",
    "print(f'  TN={tn}  FP={fp}')\n",
    "print(f'  FN={fn}  TP={tp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels=['NO (0)', 'YES (1)'])\n",
    "disp.plot(ax=axes[0], colorbar=False, cmap='Blues')\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Metrics bar chart\n",
    "metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'Specificity': specificity,\n",
    "    'ROC-AUC': roc_auc\n",
    "}\n",
    "bars = axes[1].bar(metrics.keys(), metrics.values(),\n",
    "                   color=['#3498db', '#2ecc71', '#e74c3c', '#9b59b6', '#f39c12'],\n",
    "                   edgecolor='black', alpha=0.85)\n",
    "axes[1].set_ylim(0, 1.1)\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('Model Performance Metrics', fontsize=14, fontweight='bold')\n",
    "for bar in bars:\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2,\n",
    "                 bar.get_height() + 0.02,\n",
    "                 f'{bar.get_height():.3f}', ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_evaluation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-md",
   "metadata": {},
   "source": [
    "## üèÅ 8. Conclusion\n",
    "\n",
    "### Results Summary\n",
    "\n",
    "| Metric | Score |\n",
    "|--------|-------|\n",
    "| **Accuracy** | 96.77% |\n",
    "| **Precision** | 98.33% |\n",
    "| **Recall (Sensitivity)** | 98.33% |\n",
    "| **Specificity** | 50.00% |\n",
    "| **ROC-AUC** | 0.9250 |\n",
    "\n",
    "**Confusion Matrix:** TN=1 | FP=1 | FN=1 | TP=59\n",
    "\n",
    "---\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "The Logistic Regression model demonstrates **strong predictive performance** on the lung cancer survey dataset:\n",
    "\n",
    "- **Accuracy (96.77%)** ‚Äî The model correctly classifies the vast majority of patients across 62 test samples.\n",
    "- **Precision (98.33%)** ‚Äî When the model predicts lung cancer, it is almost always correct, producing only 1 false positive in the test set.\n",
    "- **Recall (98.33%)** ‚Äî The model successfully identifies nearly all actual lung cancer cases (59 out of 60), which is critical in a medical screening context where missing a positive case has serious consequences.\n",
    "- **Specificity (50.00%)** ‚Äî The model correctly identifies only 1 out of 2 true negative cases. This is primarily driven by the severe class imbalance in the dataset (~87% positive class, with only 39 NO cases total), leaving very few negative samples in the test set to evaluate on.\n",
    "- **ROC-AUC (0.9250)** ‚Äî An AUC of 0.925 confirms that the model has excellent overall discriminative ability between cancer and non-cancer cases, well above a random baseline of 0.5.\n",
    "\n",
    "### Feature Insights\n",
    "\n",
    "Based on the learned model coefficients, the **top 5 most influential predictors** of lung cancer are:\n",
    "\n",
    "1. **Fatigue** (coef: 1.478) ‚Äî strongest positive predictor\n",
    "2. **Alcohol Consuming** (coef: 1.351)\n",
    "3. **Swallowing Difficulty** (coef: 1.335)\n",
    "4. **Chronic Disease** (coef: 1.281)\n",
    "5. **Coughing** (coef: 1.241)\n",
    "\n",
    "Notably, **Gender (Male)** had a slight negative coefficient (-0.185), suggesting males in this dataset were marginally less likely to be classified as positive after controlling for other factors. **Age** had a near-zero coefficient (0.025), indicating it adds little predictive value once symptoms are accounted for.\n",
    "\n",
    "### Limitations & Future Work\n",
    "\n",
    "- The dataset is relatively small (309 records), which limits generalizability to real-world clinical settings.\n",
    "- The severe class imbalance (~87% YES) inflates accuracy and recall while suppressing specificity. Techniques like **SMOTE**, **class weighting** (`class_weight='balanced'`), or **undersampling** could produce a more balanced model.\n",
    "- Future experiments could benchmark against **Random Forest**, **XGBoost**, or **SVM** classifiers.\n",
    "- **Cross-validation** (e.g., 5-fold) would provide a more robust and reliable performance estimate than a single train/test split.\n",
    "- Feature engineering or collection of more NO-class samples would likely improve specificity significantly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
